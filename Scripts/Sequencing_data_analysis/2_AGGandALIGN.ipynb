{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 002_sequencing_data_processing: \n",
    "\n",
    "This script aggregates the reads into the diferent unique variants counting how many reads cover each variant. After aggregation the script alignes the reads to the reference sequence.\n",
    "\n",
    "This script assumes the following folder layout\n",
    "- Home folder\n",
    "    - Scripts folder with this script\n",
    "    - Data/uni_amplicon_sequences with the reference amplicon fasta file\n",
    "    - Data/Analysis_NovaSeq/merged_reads folder with the merged and concatenated data files with the reads obtained in the previous script\n",
    "    - Data/Analysis_NovaSeq folder for the results \n",
    "    \n",
    "This script assumes the following programs are installed (paths to the executables need to be specified below):\n",
    "- Cutadapt\n",
    "- vsearch\n",
    "- Needle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import modules and check versions\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "print(pd.__name__, pd.__version__)\n",
    "\n",
    "import numpy as np\n",
    "print(np.__name__, np.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "print(matplotlib.__name__, matplotlib.__version__)\n",
    "\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "print(scipy.__name__, scipy.__version__)\n",
    "\n",
    "import re\n",
    "print(re.__name__, re.__version__)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define some helper functions that will help us for the further analysis\n",
    "def reverse_complement(dna):\n",
    "    \"\"\" function that reverse complements DNA\n",
    "    dna: input dna sequence\n",
    "    \"\"\"\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n",
    "    return ''.join([complement[base] for base in dna[::-1]])\n",
    "\n",
    "def get_dict_of_seq(fasta_file):\n",
    "    \"\"\" function that converts a fasta file to a dictionnary of sequences\n",
    "    fasta_file: the input fasta file\n",
    "    \"\"\"\n",
    "    \n",
    "    file_fasta_dict = {}\n",
    "    # output dict of imported seqs\n",
    "    \n",
    "    with open(fasta_file, 'r') as fasta:    \n",
    "        for line in fasta:\n",
    "            # loops through the file\n",
    "\n",
    "            if line.startswith('>') == True:\n",
    "                seq_info = line.strip('>').strip('\\n').split('\\t')[0]\n",
    "                file_fasta_dict[seq_info] = ''\n",
    "                # checks if seq header\n",
    "\n",
    "            else:\n",
    "                file_fasta_dict[seq_info] += line.strip('\\n')\n",
    "                # If not, append nt to current seq\n",
    "                \n",
    "    return file_fasta_dict\n",
    "\n",
    "\n",
    "os.chdir(\"/path/Novaseq_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Make a dictionary to identify the different merged files\n",
    "\n",
    "path_to_merged_files = \"./Data/Analysis_Novaseq/merged_reads\"\n",
    "\n",
    "dict_path_to_merged_files = {}\n",
    "\n",
    "for filename in os.listdir(path_to_merged_files):\n",
    "    \n",
    "    f = os.path.join(path_to_merged_files, filename)\n",
    "    \n",
    "    f1 = f.rstrip(\"_merged.fasta\")\n",
    "       \n",
    "    sample_name=f1.lstrip(\"./Data/Analysis_Novaseq/merged_reads\")\n",
    "           \n",
    "    dict_path_to_merged_files[sample_name] = f1\n",
    "    \n",
    "dict_path_to_merged_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming Using cutadapt to keep only the sequence on which we performed the DMS from position 10 to position 78. For this I use the primers as adaptors AGTAGCAATGAAGTCAGT...GTTTAAACGGTCTCCAGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create a directoty to save the trimmed files\n",
    "\n",
    "outfile_trimmed_merged_prefix = './Data/Analysis_Novaseq/trimmed_merged_reads/'\n",
    "\n",
    "os.makedirs(outfile_trimmed_merged_prefix, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## I will use cutadapt to trim the sequences using anchored adapters to remove all the sequence that are before the coding sequence. \n",
    "\n",
    "### Trim the first batch with \n",
    "trimmed_merged_list = []\n",
    "\n",
    "## Loop through the merged files\n",
    "for file in dict_path_to_merged_files.values():\n",
    "    \n",
    "    filename = file + '_merged.fasta'\n",
    "\n",
    "    filename_out = file + '_trimmed_merged.fa'\n",
    "    \n",
    "    test2=filename_out.lstrip(\"./Data/Analysis_Novaseq/merged_reads/\")\n",
    "    \n",
    "    outfile_trimmed_merged = os.path.join(outfile_trimmed_merged_prefix, test2)\n",
    "    \n",
    "    trimmed_merged_list.append(outfile_trimmed_merged)\n",
    "    \n",
    "    cutadapt_trim_call = 'cutadapt -a AGTAGCAATGAAGTCAGT...GTTTAAACGGTCTCCAGC -j 4 -o ' + outfile_trimmed_merged + \" \" + filename\n",
    "            \n",
    "    subprocess.check_output(cutadapt_trim_call, shell=True)\n",
    "    \n",
    "    print(test2)\n",
    "    print('--------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate the reads with Vsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregate_list = []\n",
    "\n",
    "aggregate_prefix = './Data/Analysis_Novaseq/aggregate_reads/'\n",
    "os.makedirs(aggregate_prefix, exist_ok = True)\n",
    "\n",
    "## Loop through the trimmed merged files and aggregate\n",
    "for trimmed_merged_file in trimmed_merged_list:\n",
    "    \n",
    "    \n",
    "    test = trimmed_merged_file.rstrip(\"trimmed_merged.fa\")\n",
    "        \n",
    "    filename_out = test + '_aggregate.fa'\n",
    "        \n",
    "    test2=filename_out.lstrip(\"./Data/Analysis_Novaseq/trimmed_merged_reads/\")\n",
    "        \n",
    "    outfile_aggregate = os.path.join(aggregate_prefix, test2)\n",
    "    \n",
    "    aggregate_list.append(outfile_aggregate)\n",
    "        \n",
    "    ## vsearch parameters:\n",
    "    # --derep_fulllength dereplicate sequences in the given fasta file\n",
    "    # --relabel add a given prefix\n",
    "    # --output output file\n",
    "    # -- sizeout include abundance information\n",
    "\n",
    "    vsearch_aggregate_call = 'vsearch --derep_fulllength ' + trimmed_merged_file + ' --relabel seq --sizeout --output '\n",
    "    vsearch_aggregate_call += outfile_aggregate\n",
    "\n",
    "    subprocess.check_output(vsearch_aggregate_call, shell=True)\n",
    "    \n",
    "    print(test2)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and aling to the reference amplicon with Needle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('./Data/Analysis_Novaseq/amplicon_align')\n",
    "\n",
    "path_to_amplicons = './Data/uni_amplicon_sequences/Novaseq_R67.fasta'\n",
    "\n",
    "amplicon_info_dict = get_dict_of_seq(path_to_amplicons)\n",
    "\n",
    "amplicon_length_dict = {}\n",
    "\n",
    "amplicon_dict = {}\n",
    "\n",
    "for amplicon in amplicon_info_dict:\n",
    "    \n",
    "    amplicon_name = amplicon.split('|')[0]\n",
    "\n",
    "    amplicon_dict[amplicon_name] = amplicon_info_dict[amplicon]\n",
    "    \n",
    "    amplicon_fasta_path = './Data/Analysis_Novaseq/amplicon_sequences/'+amplicon_name+'.fasta'\n",
    "    \n",
    "    with open(amplicon_fasta_path, 'w') as dest:\n",
    "        \n",
    "        seq_ID = '>'+amplicon_name+'\\n'\n",
    "        seq = amplicon_dict[amplicon_name]+'\\n'\n",
    "        \n",
    "        dest.write(seq_ID)\n",
    "        dest.write(seq)\n",
    "    \n",
    "\n",
    "print (amplicon_info_dict.keys())\n",
    "print (amplicon_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define a function to do the alignments with needle\n",
    "def needle_align_on_ref(ref_orf, filepath):\n",
    "    \n",
    "    \"\"\" function that creates the command and executes it in the terminal to align the aggregated reads to the reference sequence using needle \n",
    "    ref_orf: The reference sequence name to which you want to align as it apears in the key of your dictionary\n",
    "    filepath: The path to the aggregated file or the list that has the path for all the aggregate files\n",
    "    \"\"\"\n",
    "                   \n",
    "    ref_seq = amplicon_dict[ref_orf]\n",
    "    \n",
    "    ref_fasta_path = './Data/Analysis_Novaseq/amplicon_sequences/'+ref_orf+'.fasta '\n",
    "    \n",
    "    ## Get the name of the samples\n",
    "    \n",
    "    test = filepath.rstrip(\"aggregate.fa\")      \n",
    "\n",
    "    test2=test.lstrip(\"./Data/Analysis_Novaseq/aggregate_reads/\") \n",
    "    \n",
    "    test3 = test2.rstrip(\"_\")\n",
    "        \n",
    "    ## Needle arguments:\n",
    "    # -auto Turn of prompts\n",
    "    # -gapopen penalty for opening a gap\n",
    "    # -asequence one of the two input sequences to align\n",
    "    # -bsequence the second input sequence to align\n",
    "    # -aformat output format for the alignment (markx10 is an easily parseable format http://emboss.sourceforge.net/docs/themes/alnformats/align.markx10 )\n",
    "    # -outfile path to the output file\n",
    "    \n",
    "    # For the analysis_wt folder\n",
    "    needle_out = './Data/Analysis_Novaseq/amplicon_align/'+ ref_orf + '_' + test3 +'.needle'\n",
    "    \n",
    "    needle_call = 'needle -auto -gapopen 50 -asequence '+ ref_fasta_path\n",
    "    \n",
    "    needle_call += '-bsequence '+ filepath +' -aformat3 markx10 -outfile '+needle_out\n",
    "    \n",
    "    print(test3)\n",
    "        \n",
    "    subprocess.check_output(needle_call, shell = True)\n",
    "    \n",
    "    print(\"----done----\")\n",
    "          \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Run the alignments looping through the files of size filtered aggregate reads\n",
    "for filepath in aggregate_list:\n",
    "    needle_align_on_ref('Novaseq_R67_bacteria', filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUE IN THE 3_Count_variants NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
